# stPainter

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10-green)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.8-ee4c2c)](https://pytorch.org/)
[![Paper](https://img.shields.io/badge/Paper-bioRxiv-yellow)](https://www.biorxiv.org/content/10.64898/2026.02.11.704553v1)

This repository contains the official implementation and tutorial for **stPainter**.

<!-- TOC -->
* [ğŸ“– Introduction](#-introduction)
* [ğŸ› ï¸ Environment Setup](#ï¸-environment-setup)
* [ğŸ“‚ Data Preparation](#-data-preparation)
* [ğŸš€ Getting Started](#-getting-started)
* [ğŸ““ Detailed Tutorial](#-detailed-tutorial)
* [ğŸ”¥ Model Training](#-model-training)
* [ğŸ”— Citation](#-citation)
* [âœ‰ï¸ Contact](#ï¸-contact)
<!-- TOC -->

## ğŸ“– Introduction

stPainter is a deep learning framework designed to universally enhance spatial transcriptomics (ST) data across diverse histological landscapes. Leveraging a latent diffusion model pretrained on massive pan-cancer scRNA-seq datasets, stPainter enables direct application to diverse tumors without retraining. Ultimately, it yields dual outputs for each cell: an enhanced latent embedding for tasks such as fine-celltype clustering, and an imputed gene matrix for differential expression analysis, significantly enhancing the utility of single-cell resolution ST.

![Overview](figure/overview.png)

## ğŸ› ï¸ Environment Setup

We recommend using Miniconda or Anaconda to manage the environment.

### 1. Create the environment
```bash
conda create -n stpainter python=3.10 -y
conda activate stpainter
```

### 2. Install dependencies
Basic installation:
```bash
pip install -r requirements.txt
```

### 3. (Optional) Custom CUDA Installation
By default, the requirements file installs the standard version of PyTorch. If you require a specific CUDA version (e.g., **CUDA 12.6** for Flash Attention or specific GPU drivers), please install PyTorch manually:

```bash
# Example for CUDA 12.6
pip install torch==2.8.0 --index-url https://download.pytorch.org/whl/cu126
```

## ğŸ“‚ Data Preparation

Data should be organized in the `data/` directory. You can either download the preprocessed data directly or process the raw data from scratch.

### Directory Structure

Ensure your project directory looks like this:

```text
stPainter/
â””â”€â”€ data/
    â”œâ”€â”€ raw/              # Raw datasets (scRNA-seq & ST)
    â”‚   â”œâ”€â”€ sc_raw.h5ad
    â”‚   â”œâ”€â”€ st_CESC_raw.h5ad
    â”‚   â”œâ”€â”€ st_COAD_raw.h5ad
    â”‚   â”œâ”€â”€ st_LIHC_raw.h5ad
    â”‚   â”œâ”€â”€ st_NSCLC_raw.h5ad
    â”‚   â”œâ”€â”€ st_OV_raw.h5ad
    â”‚   â””â”€â”€ st_PRAD_raw.h5ad
    â””â”€â”€ processed/        # Processed files for training/testing
        â”œâ”€â”€ gene_sparsity_ratio.csv
        â”œâ”€â”€ sc_train.h5ad
        â”œâ”€â”€ st_CESC_test.h5ad
        â”œâ”€â”€ st_COAD_test.h5ad
        â”œâ”€â”€ st_LIHC_test.h5ad
        â”œâ”€â”€ st_NSCLC_test.h5ad
        â”œâ”€â”€ st_OV_test.h5ad
        â””â”€â”€ st_PRAD_test.h5ad
```

### Option 1: Use Processed Data (Recommended)

Download the preprocessed datasets directly to skip the data processing step.

1. [Download](https://drive.google.com/drive/folders/1ROePTWXUtuZWIrbLF6HLf34cRaLjGTCw?usp=share_link) the processed data and move the files into the `./data/processed/` directory.
2. Ensure `gene_sparsity_ratio.csv` and the `.h5ad` files are present as shown in the structure above.

### Option 2: Process from Scratch

If you prefer to process the raw data yourself:

1. Download([COAD, OV, LIHC](https://spatch.pku-genomics.org/), [PRAD](https://www.10xgenomics.com/datasets/xenium-prime-ffpe-human-prostate), [NSCLC](https://www.10xgenomics.com/datasets/xenium-human-lung-cancer-post-xenium-technote), and [CESC](https://www.10xgenomics.com/datasets/xenium-prime-ffpe-human-cervical-cancer)) the raw data and move the files into the `./data/raw/` directory.
2. Use the provided script to generate the training and testing files.

```bash
python process_data.py --raw_data_dir ./data/raw/ --processed_data_dir ./data/processed
```

## ğŸš€ Getting Started

This section guides you through using the pretrained stPainter models to impute gene expression and evaluate the results.

### 1. Download Pretrained Models

[Download](https://drive.google.com/drive/folders/1ROePTWXUtuZWIrbLF6HLf34cRaLjGTCw?usp=share_link) the pretrained model weights. After downloading, ensure the `checkpoint/` directory is organized as follows:

```text
stPainter/
â””â”€â”€ checkpoint/
    â”œâ”€â”€ diffusion_50.ckpt
    â”œâ”€â”€ diffusion_100.ckpt
    â”œâ”€â”€ vae_50.ckpt
    â””â”€â”€ vae_100.ckpt
```

**Note:** Before proceeding, ensure you have placed the model checkpoints in the `./checkpoint/` directory and prepared the data as described in [Data Preparation](#-data-preparation).

### 2. Gene Imputation

Use `impute_stPainter.py` to generate imputed gene expression matrices. The following example uses the model with a latent size of **50** on the COAD dataset.

```bash
python impute_stPainter.py \
    --diffusion_checkpoint checkpoint/diffusion_50.ckpt \
    --vae_checkpoint checkpoint/vae_50.ckpt \
    --latent_size 50 \
    --input_path ./data/processed/st_COAD_test.h5ad \
    --output_path ./data/imputed_50/st_COAD_imputed.h5ad \
    --cancer_type COAD
```

*Tip: To use the 100-dimensional model, simply change `--latent_size` to 100 and update the checkpoint paths accordingly.*

### 3. Testing & Evaluation

To evaluate the model's performance and generate metrics, run the test script:

```bash
python test_stPainter.py \
    --diffusion_checkpoint checkpoint/diffusion_50.ckpt \
    --vae_checkpoint checkpoint/vae_50.ckpt \
    --latent_size 50 \
    --input_path ./data/processed/st_COAD_test.h5ad \
    --result_dir ./test/stPainter_50 \
    --cancer_type COAD
```

## ğŸ““ Detailed Tutorial
TODO

## ğŸ”¥ Model Training

If you wish to train stPainter from scratch (e.g., using a custom single-cell reference atlas), follow the two-stage training process outlined below.

**Note:** Ensure the `--latent_size` parameter is consistent across both steps (e.g., 50 or 100).

### Step 1: Pretrain VAE

First, train the Variational Autoencoder (VAE) to compress high-dimensional gene expression profiles into a compact latent space.

```bash
python train_vae.py \
    --data_path ./data/processed/sc_train.h5ad \
    --latent_size 50
```

### Step 2: Pretrain Diffusion Model

Next, train the Gene Diffusion Transformer (GiT) to learn the distribution of the VAE's latent representations.

**Note:** This step requires the VAE checkpoint generated in Step 1.

```bash
python train_diffusion.py \
    --vae_checkpoint ./checkpoint/vae_50.ckpt \
    --data_path ./data/processed/sc_train.h5ad \
    --latent_size 50
```

## ğŸ”— Citation

If you find this work useful in your research, please consider citing:

```bibtex
@article {Yang2026.02.11.704553,
	author = {Yang, Yuhang and Luo, Yiming and Zhang, Kai and Zhang, Zaixi and Peng, Haoxin and Cao, Chenlin and Liu, Qi and Ma, Bin and Chen, Yang and Shen, Lin and Chen, Enhong},
	title = {Enhancing Pan-cancer Spatial Transcriptomics at Single-cell Resolution with stPainter},
	year = {2026},
	doi = {10.64898/2026.02.11.704553},
	journal = {bioRxiv}
}
```

## âœ‰ï¸ Contact

If you have any questions or encounter issues, please feel free to:
* Open an issue in this repository.
* Contact us via email: [yyh20030806@mail.ustc.edu.cn](mailto:yyh20030806@mail.ustc.edu.cn).
